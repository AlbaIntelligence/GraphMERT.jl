"""
Comprehensive Integration Test for Full GraphMERT Pipeline

This test verifies the complete end-to-end workflow:
1. Text preprocessing and leafy chain graph creation
2. Entity extraction and UMLS linking
3. Relation extraction and matching
4. Knowledge graph construction
5. Evaluation with FActScore and ValidityScore
6. Batch processing and result merging
7. Model training simulation
8. Performance validation

This test ensures all components work together seamlessly.
"""

using Test
using GraphMERT
using Dates
using Statistics: mean, std

# Test data
const INTEGRATION_TEST_TEXT = """
Diabetes mellitus is a chronic metabolic disorder characterized by elevated blood glucose levels.
The condition affects millions of people worldwide and is a leading cause of cardiovascular disease,
kidney failure, and blindness. Type 2 diabetes, the most common form, is often associated with
obesity and insulin resistance. Treatment typically involves lifestyle modifications, oral medications
like metformin, and in some cases, insulin therapy. Regular monitoring of blood glucose levels is
essential for effective diabetes management. Complications can include diabetic neuropathy,
retinopathy, and nephropathy, making early detection and treatment crucial for patient outcomes.
"""

const MULTIPLE_DOCUMENTS = [
  "Patient with type 2 diabetes presents with elevated blood glucose requiring metformin therapy.",
  "Insulin resistance is a key feature of type 2 diabetes mellitus in obese patients.",
  "Cardiovascular complications are common in patients with long-standing diabetes.",
  "Diabetic nephropathy screening shows microalbuminuria in type 1 diabetes patients.",
  "Gestational diabetes affects 2-10% of pregnancies and requires careful monitoring."
]

@testset "Full GraphMERT Pipeline Integration Test" begin

  @testset "1. Text Preprocessing and Leafy Chain Creation" begin
    println("ðŸ§¬ Testing leafy chain graph creation...")

    # Create leafy chain graph from text
    graph = create_leafy_chain_from_text(INTEGRATION_TEST_TEXT)

    @test graph !== nothing
    @test length(graph.root_nodes) > 0
    @test length(graph.leaf_nodes) > 0
    @test length(graph.root_nodes) * 7 == length(graph.leaf_nodes)  # 7 leaves per root

    println("   âœ… Leafy chain graph created successfully")
    println("   â€¢ Roots: $(length(graph.root_nodes))")
    println("   â€¢ Leaves: $(length(graph.leaf_nodes))")
    println("   â€¢ Total nodes: $(length(graph.root_nodes) + length(graph.leaf_nodes))")
  end

  @testset "2. Entity Extraction and UMLS Linking" begin
    println("ðŸ” Testing entity extraction...")

    # Extract entities from text
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)

    @test length(entities) > 0
    @test all(e isa BiomedicalEntity for e in entities)
    @test all(0.0 <= e.confidence <= 1.0 for e in entities)

    # Verify entity properties
    for entity in entities
      @test !isempty(entity.text)
      @test !isempty(entity.label)
      @test entity.position.start >= 1
      @test entity.position.stop >= entity.position.start
    end

    println("   âœ… Entity extraction successful")
    println("   â€¢ Entities found: $(length(entities))")
    println("   â€¢ Average confidence: $(round(mean([e.confidence for e in entities]), digits=3))")

    # Test UMLS linking (mock)
    umls_client = create_umls_client("test_api_key")
    @test umls_client !== nothing

    println("   âœ… UMLS client created successfully")
  end

  @testset "3. Relation Extraction and Matching" begin
    println("ðŸ”— Testing relation extraction...")

    # Extract entities first
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)

    # Match relations between entities
    relations = match_relations_for_entities(entities, INTEGRATION_TEST_TEXT)

    @test length(relations) >= 0  # May be 0 if no relations found
    @test all(r isa BiomedicalRelation for r in relations)

    # Verify relation properties
    for relation in relations
      @test !isempty(relation.head)
      @test !isempty(relation.tail)
      @test !isempty(relation.relation_type)
      @test 0.0 <= relation.confidence <= 1.0
    end

    println("   âœ… Relation extraction successful")
    println("   â€¢ Relations found: $(length(relations))")
    if !isempty(relations)
      println("   â€¢ Average confidence: $(round(mean([r.confidence for r in relations]), digits=3))")
    end
  end

  @testset "4. Knowledge Graph Construction" begin
    println("ðŸ“Š Testing knowledge graph construction...")

    # Extract entities and relations
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)
    relations = match_relations_for_entities(entities, INTEGRATION_TEST_TEXT)

    # Create knowledge graph
    metadata = Dict{String,Any}(
      "source" => "integration_test",
      "extraction_time" => now(),
      "text_length" => length(INTEGRATION_TEST_TEXT)
    )

    kg = KnowledgeGraph(entities, relations, metadata)

    @test kg !== nothing
    @test length(kg.entities) == length(entities)
    @test length(kg.relations) == length(relations)
    @test haskey(kg.metadata, "source")
    @test kg.metadata["source"] == "integration_test"

    println("   âœ… Knowledge graph constructed successfully")
    println("   â€¢ Entities: $(length(kg.entities))")
    println("   â€¢ Relations: $(length(kg.relations))")
    println("   â€¢ Metadata keys: $(length(kg.metadata))")
  end

  @testset "5. Evaluation with FActScore and ValidityScore" begin
    println("ðŸ“ˆ Testing evaluation metrics...")

    # Create test knowledge graph
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)
    relations = match_relations_for_entities(entities, INTEGRATION_TEST_TEXT)
    kg = KnowledgeGraph(entities, relations, Dict{String,Any}("source" => "test"))

    # Test FActScore evaluation
    factscore_result = evaluate_factscore(kg, INTEGRATION_TEST_TEXT)

    @test factscore_result !== nothing
    @test 0.0 <= factscore_result.factscore <= 1.0
    @test factscore_result.total_triples >= 0
    @test factscore_result.supported_triples >= 0
    @test factscore_result.supported_triples <= factscore_result.total_triples

    println("   âœ… FActScore evaluation successful")
    println("   â€¢ FActScore: $(round(factscore_result.factscore * 100, digits=1))%")
    println("   â€¢ Total triples: $(factscore_result.total_triples)")
    println("   â€¢ Supported triples: $(factscore_result.supported_triples)")

    # Test ValidityScore evaluation
    validity_result = evaluate_validity(kg)

    @test validity_result !== nothing
    @test 0.0 <= validity_result.validity_score <= 1.0
    @test validity_result.total_triples >= 0
    @test validity_result.valid_triples >= 0
    @test validity_result.valid_triples <= validity_result.total_triples

    println("   âœ… ValidityScore evaluation successful")
    println("   â€¢ ValidityScore: $(round(validity_result.validity_score * 100, digits=1))%")
    println("   â€¢ Total triples: $(validity_result.total_triples)")
    println("   â€¢ Valid triples: $(validity_result.valid_triples)")
  end

  @testset "6. Batch Processing and Result Merging" begin
    println("ðŸš€ Testing batch processing...")

    # Test batch processing configuration
    config = create_batch_processing_config(
      batch_size=2,
      max_memory_mb=512,
      num_threads=1,
      memory_monitoring=true,
      auto_optimize=true
    )

    @test config !== nothing
    @test config.batch_size == 2
    @test config.max_memory_mb == 512
    @test config.num_threads == 1

    # Mock extraction function for testing
    function mock_extract_knowledge_graph(doc::String)
      entities = discover_head_entities(doc)
      relations = match_relations_for_entities(entities, doc)
      return KnowledgeGraph(entities, relations, Dict{String,Any}("source" => doc))
    end

    # Test batch processing
    batch_result = extract_knowledge_graph_batch(
      MULTIPLE_DOCUMENTS,
      config=config,
      extraction_function=mock_extract_knowledge_graph
    )

    @test batch_result !== nothing
    @test batch_result.total_documents == length(MULTIPLE_DOCUMENTS)
    @test batch_result.successful_batches >= 0
    @test batch_result.failed_batches >= 0
    @test batch_result.total_time > 0
    @test batch_result.average_throughput > 0
    @test length(batch_result.knowledge_graphs) == 1  # Merged result

    println("   âœ… Batch processing successful")
    println("   â€¢ Total documents: $(batch_result.total_documents)")
    println("   â€¢ Successful batches: $(batch_result.successful_batches)")
    println("   â€¢ Failed batches: $(batch_result.failed_batches)")
    println("   â€¢ Total time: $(round(batch_result.total_time, digits=2))s")
    println("   â€¢ Average throughput: $(round(batch_result.average_throughput, digits=2)) docs/s")

    # Test result merging
    merged_kg = batch_result.knowledge_graphs[1]
    @test merged_kg !== nothing
    @test length(merged_kg.entities) >= 0
    @test length(merged_kg.relations) >= 0

    println("   âœ… Result merging successful")
    println("   â€¢ Merged entities: $(length(merged_kg.entities))")
    println("   â€¢ Merged relations: $(length(merged_kg.relations))")
  end

  @testset "7. Model Training Simulation" begin
    println("ðŸ‹ï¸ Testing model training simulation...")

    # Test MNM training configuration
    mnm_config = MNMConfig(30522, 512, 7, 0.15, 0.3)
    @test mnm_config !== nothing
    @test mnm_config.vocab_size == 30522
    @test mnm_config.hidden_size == 512
    @test mnm_config.num_leaves == 7

    # Test leafy chain graph creation for training
    graph = create_leafy_chain_from_text(INTEGRATION_TEST_TEXT)
    @test graph !== nothing

    # Test MNM batch creation (mock the required parameters)
    mock_sequences = [[(1, 2), (3, 4)]]  # Mock sequence data
    mock_attention_masks = [[1, 1, 1, 1]]  # Mock attention masks
    batch = create_mnm_batch([graph], mock_sequences, mock_attention_masks, mnm_config)
    @test batch !== nothing
    @test size(batch.graph_sequence)[1] == 1  # Batch size
    @test size(batch.graph_sequence)[2] == 1024  # Sequence length

    println("   âœ… MNM training simulation successful")
    println("   â€¢ Graph nodes: $(length(graph.root_nodes) + length(graph.leaf_nodes))")
    println("   â€¢ Batch shape: $(size(batch.graph_sequence))")
    println("   â€¢ Attention mask shape: $(size(batch.attention_mask))")

    # Test seed injection simulation
    seed_config = SeedInjectionConfig(0.8, 0.7, 40, 0.3, 0.2)
    @test seed_config !== nothing

    # Mock seed triples
    seed_triples = [
      SemanticTriple("diabetes", "treats", "metformin", 0.9, "seed_kg"),
      SemanticTriple("diabetes", "causes", "complications", 0.8, "seed_kg")
    ]

    # Test seed injection
    injected_graph = inject_seed_kg(graph, seed_triples, seed_config)
    @test injected_graph !== nothing

    println("   âœ… Seed injection simulation successful")
    println("   â€¢ Seed triples: $(length(seed_triples))")
    println("   â€¢ Injected graph nodes: $(length(injected_graph.root_nodes) + length(injected_graph.leaf_nodes))")
  end

  @testset "8. Performance Validation" begin
    println("âš¡ Testing performance validation...")

    # Test processing speed
    start_time = time()
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)
    processing_time = time() - start_time

    @test processing_time > 0
    @test processing_time < 10.0  # Should be fast

    # Test memory usage
    initial_memory = Base.gc_live_bytes() / 1024^2  # MB
    kg = KnowledgeGraph(entities, BiomedicalRelation[], Dict{String,Any}("test" => true))
    peak_memory = Base.gc_live_bytes() / 1024^2  # MB
    memory_usage = peak_memory - initial_memory

    @test memory_usage >= 0
    @test memory_usage < 100  # Should be reasonable

    println("   âœ… Performance validation successful")
    println("   â€¢ Processing time: $(round(processing_time * 1000, digits=2)) ms")
    println("   â€¢ Memory usage: $(round(memory_usage, digits=2)) MB")
    println("   â€¢ Text length: $(length(INTEGRATION_TEST_TEXT)) characters")
    println("   â€¢ Entities extracted: $(length(entities))")
  end

  @testset "9. Error Handling and Edge Cases" begin
    println("ðŸ›¡ï¸ Testing error handling...")

    # Test empty text
    empty_entities = discover_head_entities("")
    @test length(empty_entities) == 0

    # Test very short text
    short_entities = discover_head_entities("Hi")
    @test length(short_entities) >= 0  # May or may not find entities

    # Test batch processing with empty documents
    empty_docs = [""]
    config = create_batch_processing_config(batch_size=1, max_memory_mb=256)

    function mock_empty_extract(doc::String)
      if isempty(doc)
        return KnowledgeGraph(BiomedicalEntity[], BiomedicalRelation[],
          Dict{String,Any}("empty" => true))
      end
      entities = discover_head_entities(doc)
      return KnowledgeGraph(entities, [], Dict{String,Any}("source" => doc))
    end

    empty_result = extract_knowledge_graph_batch(empty_docs, config=config,
      extraction_function=mock_empty_extract)
    @test empty_result !== nothing
    @test empty_result.total_documents == 1

    println("   âœ… Error handling successful")
    println("   â€¢ Empty text handled: $(length(empty_entities) == 0)")
    println("   â€¢ Short text handled: $(length(short_entities) >= 0)")
    println("   â€¢ Empty batch processed: $(empty_result.total_documents == 1)")
  end

  @testset "10. Integration Workflow Summary" begin
    println("ðŸ“‹ Integration workflow summary...")

    # Complete workflow simulation
    workflow_start = time()

    # Step 1: Text preprocessing
    graph = create_leafy_chain_from_text(INTEGRATION_TEST_TEXT)

    # Step 2: Entity extraction
    entities = discover_head_entities(INTEGRATION_TEST_TEXT)

    # Step 3: Relation extraction
    relations = match_relations_for_entities(entities, INTEGRATION_TEST_TEXT)

    # Step 4: Knowledge graph construction
    kg = KnowledgeGraph(entities, relations, Dict{String,Any}("workflow" => "complete"))

    # Step 5: Evaluation
    factscore_result = evaluate_factscore(kg, INTEGRATION_TEST_TEXT)
    validity_result = evaluate_validity(kg)

    # Step 6: Batch processing
    batch_result = extract_knowledge_graph_batch(
      MULTIPLE_DOCUMENTS,
      config=create_batch_processing_config(batch_size=2),
      extraction_function=(doc -> KnowledgeGraph(discover_head_entities(doc), [], Dict{String,Any}("source" => doc)))
    )

    workflow_time = time() - workflow_start

    @test workflow_time > 0
    @test workflow_time < 30.0  # Should complete in reasonable time

    println("   âœ… Complete workflow successful")
    println("   â€¢ Total workflow time: $(round(workflow_time, digits=2))s")
    println("   â€¢ Graph nodes created: $(length(graph.root_nodes) + length(graph.leaf_nodes))")
    println("   â€¢ Entities extracted: $(length(entities))")
    println("   â€¢ Relations extracted: $(length(relations))")
    println("   â€¢ FActScore: $(round(factscore_result.factscore * 100, digits=1))%")
    println("   â€¢ ValidityScore: $(round(validity_result.validity_score * 100, digits=1))%")
    println("   â€¢ Batch documents processed: $(batch_result.total_documents)")

    # Final validation
    @test length(entities) > 0
    @test length(relations) >= 0
    @test factscore_result.factscore >= 0.0
    @test validity_result.validity_score >= 0.0
    @test batch_result.total_documents == length(MULTIPLE_DOCUMENTS)

    println("   ðŸŽ‰ All integration tests passed!")
    println("   GraphMERT pipeline is fully functional!")
  end
end

println("âœ… Full GraphMERT Pipeline Integration Test Complete!")
println("All components working together seamlessly!")
